{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nimori/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "#import textblob\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using texts and lables\n",
    "\n",
    "df= pd.read_csv('data_1000.csv')\n",
    "df2= pd.DataFrame()\n",
    "df2['text']= df['post_description_en']\n",
    "df2['labels']= df['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['labels']= df2['labels'].replace('Journalist, Writing And Translation', 'Government Works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agriculture And Farming</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artist</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brokering / Agent</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Phone Internet</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education And Skill Development</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fisheries And Animal Husbandry</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forest &amp; Environment</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Government Works</th>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare And Medicine</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plumber</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sanitation Works</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Service</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel And Transport</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text\n",
       "labels                               \n",
       "Agriculture And Farming             1\n",
       "Artist                              3\n",
       "Brokering / Agent                   1\n",
       "Computer Phone Internet            51\n",
       "Education And Skill Development   142\n",
       "Fisheries And Animal Husbandry     13\n",
       "Forest & Environment               15\n",
       "Government Works                  298\n",
       "Healthcare And Medicine           391\n",
       "Labor                               1\n",
       "Plumber                             1\n",
       "Sanitation Works                    1\n",
       "Social Service                     74\n",
       "Travel And Transport                8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('labels').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df2[(df2.labels!='Agriculture And Farming')& (df2.labels!='Artist')& (df2.labels!='Brokering / Agent')& (df2.labels!='Labor')& (df2.labels!='Plumber')& (df2.labels!='Sanitation Works')& (df2.labels!='Travel And Transport')]\n",
    "#We remove all those categories whose count is in single digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Computer Phone Internet</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education And Skill Development</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fisheries And Animal Husbandry</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forest &amp; Environment</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Government Works</th>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare And Medicine</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Service</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text\n",
       "labels                               \n",
       "Computer Phone Internet            51\n",
       "Education And Skill Development   142\n",
       "Fisheries And Animal Husbandry     13\n",
       "Forest & Environment               15\n",
       "Government Works                  298\n",
       "Healthcare And Medicine           391\n",
       "Social Service                     74"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('labels').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= pd.read_csv('report_04-11.csv')\n",
    "#len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_04= pd.DataFrame()\n",
    "df_04['text']= df3['translation']\n",
    "df_04['labels']= df3['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_04['labels']= df_04['labels'].apply(lambda x: x.lower())\n",
    "df_04['text']= df_04['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(a):\n",
    "    list2 = nltk.word_tokenize(a)  \n",
    "    a_lemma = ' '.join([lemmatizer.lemmatize(words) for words in list2])\n",
    "    rem_punc= [char for char in a_lemma if char not in string.punctuation]\n",
    "    rem_punc= ''.join(rem_punc)\n",
    "    return [word for word in rem_punc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/nimori/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords= set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_04['text_cleaned']= df_04.iloc[:,0].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df_04.iterrows():\n",
    "    row['text_cleaned']= ' '.join([str(elem) for elem in row['text_cleaned']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@ceonagaland  briefs media after closing of b...</td>\n",
       "      <td>computer phone internet</td>\n",
       "      <td>ceonagaland brief medium closing byeelection d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patrolling on river ganga and gandak at sonpur...</td>\n",
       "      <td>fisheries and animal husbandry</td>\n",
       "      <td>patrolling river ganga gandak sonpur alectiond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shri vinay kumar tripathi, general manager, no...</td>\n",
       "      <td>safety and security</td>\n",
       "      <td>shri vinay kumar tripathi general manager nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the bye-election to the 14 southern angami-i a...</td>\n",
       "      <td>politics</td>\n",
       "      <td>byeelection 14 southern angamii ac wa conducte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voters in samastipur, playing their part in de...</td>\n",
       "      <td>government works</td>\n",
       "      <td>voter samastipur playing part democracy differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>when shopping in the market, follow all necess...</td>\n",
       "      <td>safety and security</td>\n",
       "      <td>shopping market follow necessary safety measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>online application for admission in sainik sch...</td>\n",
       "      <td>education and skill development</td>\n",
       "      <td>online application admission sainik school amb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>the 12th episode of lokvani, the monthly radio...</td>\n",
       "      <td>education and skill development</td>\n",
       "      <td>12th episode lokvani monthly radio talk chief ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>haryana government @mlkhattar has sanctioned r...</td>\n",
       "      <td>agriculture and farming</td>\n",
       "      <td>haryana government mlkhattar ha sanctioned r 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>a squirrel is a small-sized animal found in ab...</td>\n",
       "      <td>fisheries and animal husbandry</td>\n",
       "      <td>squirrel smallsized animal found abundance asi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    .@ceonagaland  briefs media after closing of b...   \n",
       "1    patrolling on river ganga and gandak at sonpur...   \n",
       "2    shri vinay kumar tripathi, general manager, no...   \n",
       "3    the bye-election to the 14 southern angami-i a...   \n",
       "4    voters in samastipur, playing their part in de...   \n",
       "..                                                 ...   \n",
       "99   when shopping in the market, follow all necess...   \n",
       "100  online application for admission in sainik sch...   \n",
       "101  the 12th episode of lokvani, the monthly radio...   \n",
       "102  haryana government @mlkhattar has sanctioned r...   \n",
       "103  a squirrel is a small-sized animal found in ab...   \n",
       "\n",
       "                              labels  \\\n",
       "0            computer phone internet   \n",
       "1     fisheries and animal husbandry   \n",
       "2                safety and security   \n",
       "3                           politics   \n",
       "4                   government works   \n",
       "..                               ...   \n",
       "99               safety and security   \n",
       "100  education and skill development   \n",
       "101  education and skill development   \n",
       "102          agriculture and farming   \n",
       "103   fisheries and animal husbandry   \n",
       "\n",
       "                                          text_cleaned  \n",
       "0    ceonagaland brief medium closing byeelection d...  \n",
       "1    patrolling river ganga gandak sonpur alectiond...  \n",
       "2    shri vinay kumar tripathi general manager nort...  \n",
       "3    byeelection 14 southern angamii ac wa conducte...  \n",
       "4    voter samastipur playing part democracy differ...  \n",
       "..                                                 ...  \n",
       "99   shopping market follow necessary safety measur...  \n",
       "100  online application admission sainik school amb...  \n",
       "101  12th episode lokvani monthly radio talk chief ...  \n",
       "102  haryana government mlkhattar ha sanctioned r 4...  \n",
       "103  squirrel smallsized animal found abundance asi...  \n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text_cleaned']= df2.iloc[:,0].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df2.iterrows():\n",
    "    row['text_cleaned']= ' '.join([str(elem) for elem in row['text_cleaned']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['labels']= df2['labels'].apply(lambda x: x.lower())\n",
    "df2['text']= df2['text'].apply(lambda x: x.lower())\n",
    "df2['text_cleaned']= df2['text_cleaned'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#covid19 report of #solapur city. @mahadgipr @...</td>\n",
       "      <td>government works</td>\n",
       "      <td>covid19 report solapur city mahadgipr infodivp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ðŸ“š dastan-e-raza library ðŸ“š\\n \\npage 17\\n\\nastro...</td>\n",
       "      <td>social service</td>\n",
       "      <td>ðŸ“š dastaneraza library ðŸ“š page 17 astronomical i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job seekers register now at https://t.co/der9r...</td>\n",
       "      <td>government works</td>\n",
       "      <td>job seeker register http tcoder9rdaue5 employm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># covid19 report of #solapur district. @mahadg...</td>\n",
       "      <td>government works</td>\n",
       "      <td>covid19 report solapur district mahadgipr maha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@15thfincom headed by chairman @nksingh_mp con...</td>\n",
       "      <td>healthcare and medicine</td>\n",
       "      <td>15thfincom headed chairman nksinghmp concludes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>keshubhai patel was a popular leader and skill...</td>\n",
       "      <td>education and skill development</td>\n",
       "      <td>keshubhai patel wa popular leader skilled orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>parks etc. have also been opened to the public...</td>\n",
       "      <td>computer phone internet</td>\n",
       "      <td>parks etc also opened public unlock 5 situatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>#worldstrokeday2020 \\n#smoking #tobacco increa...</td>\n",
       "      <td>government works</td>\n",
       "      <td>worldstrokeday2020 smoking tobacco increase ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>on behalf of the rural development and panchay...</td>\n",
       "      <td>education and skill development</td>\n",
       "      <td>behalf rural development panchayat department ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>the small imambara, which attracts every touri...</td>\n",
       "      <td>government works</td>\n",
       "      <td>small imambara attracts every tourist fine car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    #covid19 report of #solapur city. @mahadgipr @...   \n",
       "1    ðŸ“š dastan-e-raza library ðŸ“š\\n \\npage 17\\n\\nastro...   \n",
       "2    job seekers register now at https://t.co/der9r...   \n",
       "3    # covid19 report of #solapur district. @mahadg...   \n",
       "4    @15thfincom headed by chairman @nksingh_mp con...   \n",
       "..                                                 ...   \n",
       "995  keshubhai patel was a popular leader and skill...   \n",
       "996  parks etc. have also been opened to the public...   \n",
       "997  #worldstrokeday2020 \\n#smoking #tobacco increa...   \n",
       "998  on behalf of the rural development and panchay...   \n",
       "999  the small imambara, which attracts every touri...   \n",
       "\n",
       "                              labels  \\\n",
       "0                   government works   \n",
       "1                     social service   \n",
       "2                   government works   \n",
       "3                   government works   \n",
       "4            healthcare and medicine   \n",
       "..                               ...   \n",
       "995  education and skill development   \n",
       "996          computer phone internet   \n",
       "997                 government works   \n",
       "998  education and skill development   \n",
       "999                 government works   \n",
       "\n",
       "                                          text_cleaned  \n",
       "0    covid19 report solapur city mahadgipr infodivp...  \n",
       "1    ðŸ“š dastaneraza library ðŸ“š page 17 astronomical i...  \n",
       "2    job seeker register http tcoder9rdaue5 employm...  \n",
       "3    covid19 report solapur district mahadgipr maha...  \n",
       "4    15thfincom headed chairman nksinghmp concludes...  \n",
       "..                                                 ...  \n",
       "995  keshubhai patel wa popular leader skilled orga...  \n",
       "996  parks etc also opened public unlock 5 situatio...  \n",
       "997  worldstrokeday2020 smoking tobacco increase ri...  \n",
       "998  behalf rural development panchayat department ...  \n",
       "999  small imambara attracts every tourist fine car...  \n",
       "\n",
       "[984 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df2['text_cleaned'], df2['labels'], test_size=0.25, random_state=0, stratify= df2['labels'])\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# sss = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "# sss.get_n_splits(X, y)\n",
    "# for train_index, test_index in sss.split(X, y):\n",
    "#     #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     train_x, valid_x = X[train_index], X[test_index]\n",
    "#     train_y, valid_y = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test= df_04.text_cleaned\n",
    "y_test= df_04.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "#count_vect.fit(df2['text_cleaned'])\n",
    "count_vect.fit(train_x)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)\n",
    "xtest_count =  count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimori/venv_envs/tf24/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:506: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df2['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "xtest_tfidf =  tfidf_vect.transform(x_test)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(df2['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "xtest_tfidf_ngram =  tfidf_vect_ngram.transform(x_test)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(df2['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) \n",
    "xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(df2['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.6341463414634146\n",
      "NB, WordLevel TF-IDF:  0.5934959349593496\n",
      "NB, N-Gram Vectors:  0.5813008130081301\n",
      "NB, CharLevel Vectors:  0.491869918699187\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.6626016260162602\n",
      "LR, WordLevel TF-IDF:  0.6219512195121951\n",
      "LR, N-Gram Vectors:  0.5813008130081301\n",
      "LR, CharLevel Vectors:  0.6463414634146342\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.5772357723577236\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.6382113821138211\n",
      "RF, WordLevel TF-IDF:  0.6504065040650406\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
